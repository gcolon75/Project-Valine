#!/usr/bin/env python3
"""
Phase 5 Staging Super-Agent

Mission: Speedrun the Phase 5 staging checks with receipts. Execute Steps 3‚Äì8 
of the staging validation runner, apply the double-check framework for robustness, 
and ensure Discord slash commands are correctly registered and visible in the 
staging guild. Output a single, clean report with actionable fixes. No leaking secrets.

This agent combines:
1. Phase 5 validation steps (Steps 3-8) from phase5_staging_validator.py
2. Discord slash commands validation from validate_discord_slash_commands.py  
3. Double-check framework for dual verification of all checks
4. Comprehensive reporting with all evidence and remediation steps

Usage:
    python phase5_super_agent.py run --config super_agent_config.json
    python phase5_super_agent.py generate-config
    python phase5_super_agent.py --help
"""

import os
import sys
import json
import time
import argparse
import hashlib
import subprocess
import re
import requests
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any, Union, Tuple
from dataclasses import dataclass, asdict, field
from pathlib import Path
import traceback

# ============================================
# Configuration and Data Classes
# ============================================

@dataclass
class SuperAgentConfig:
    """Configuration for Phase 5 Super-Agent"""
    # Repository
    repo: str = "gcolon75/Project-Valine"
    base_ref: str = "main"
    
    # Staging URLs
    staging_urls: List[str] = field(default_factory=lambda: [
        "https://staging.example.com",
        "https://staging.example.com/api/health"
    ])
    staging_region: Optional[str] = "us-west-2"
    
    # AWS Configuration
    aws_region: str = "us-west-2"
    ssm_parameter_prefix: str = "/valine/staging/"
    log_group_name: str = "/aws/lambda/pv-api-prod-api"
    lambda_function_name: str = "pv-api-prod-api"
    
    # Discord Configuration
    discord_bot_token: Optional[str] = None  # ENV:DISCORD_BOT_TOKEN
    discord_app_id: Optional[str] = None     # ENV:DISCORD_APP_ID
    discord_guild_id: Optional[str] = None   # ENV:DISCORD_GUILD_ID_STAGING
    discord_alert_channel_id: Optional[str] = "1428102811832553554"
    
    # GitHub Configuration
    github_token: Optional[str] = None       # ENV:GITHUB_TOKEN
    github_workflows: List[str] = field(default_factory=list)
    
    # Timeouts (milliseconds)
    timeout_action_dispatch: int = 600000    # 10 minutes
    timeout_http: int = 15000                # 15 seconds
    timeout_discord_propagation: int = 60000 # 60 seconds
    
    # Flags
    dry_run: bool = False
    verbose: bool = True
    redaction_enabled: bool = True
    
    # Evidence output
    evidence_output_dir: str = "./validation_evidence"
    correlation_id_prefix: str = "SUPER-AGENT"

@dataclass
class CheckResult:
    """Result of a validation check"""
    name: str
    status: str  # PASS, FAIL, SKIP, WARNING
    primary_result: Optional[Any] = None
    secondary_result: Optional[Any] = None
    consistent: bool = True
    duration_ms: float = 0
    error: Optional[str] = None
    details: Dict[str, Any] = field(default_factory=dict)
    timestamp: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
    
@dataclass
class ValidationReport:
    """Complete validation report"""
    timestamp: str
    correlation_id: str
    config: Dict[str, Any]
    steps: List[CheckResult]
    discord_commands: Dict[str, Any]
    issues: List[Dict[str, Any]]
    remediation: List[str]
    artifacts: List[str]
    summary: str

# ============================================
# Redaction Utilities
# ============================================

def redact_secrets(data: Union[str, Dict, List, Any], show_last_n: int = 4) -> Union[str, Dict, List, Any]:
    """
    Redact secrets from data, showing only last N characters.
    
    Patterns to redact:
    - token, secret, password, key, authorization, bearer
    - Anything matching (?i)(token|secret|key|password|bearer)[=: ]\\S+
    """
    secret_patterns = [
        'token', 'secret', 'password', 'key', 'authorization',
        'bearer', 'api_key', 'access_token', 'refresh_token',
        'webhook_url', 'bot_token', 'github_token', 'discord_token',
        'cookie', 'session', 'auth'
    ]
    
    def _redact_value(value: str, force: bool = False) -> str:
        """Redact a single string value"""
        if not isinstance(value, str) or len(value) <= show_last_n:
            return value
        
        if force or re.search(r'[a-zA-Z0-9_-]{8,}', value):
            return f"***{value[-show_last_n:]}"
        return value
    
    def _should_redact(key: str) -> bool:
        """Check if a key should be redacted"""
        key_lower = key.lower()
        return any(pattern in key_lower for pattern in secret_patterns)
    
    # Handle different data types
    if isinstance(data, dict):
        return {
            key: _redact_value(val, force=True) if isinstance(val, str) and _should_redact(key)
            else redact_secrets(val, show_last_n)
            for key, val in data.items()
        }
    elif isinstance(data, list):
        return [redact_secrets(item, show_last_n) for item in data]
    elif isinstance(data, str):
        # Redact inline patterns like "Authorization: Bearer token123"
        result = data
        for pattern_name in ['token', 'secret', 'key', 'password', 'bearer']:
            pattern = rf'(?i)({pattern_name}[=: ])(\S+)'
            result = re.sub(pattern, lambda m: f"{m.group(1)}***{m.group(2)[-show_last_n:]}", result)
        return result
    else:
        return data

# ============================================
# Phase 5 Super-Agent Main Class
# ============================================

class Phase5SuperAgent:
    """
    Phase 5 Staging Super-Agent
    
    Executes Steps 3-8 with double-check framework and Discord command validation.
    """
    
    def __init__(self, config: SuperAgentConfig):
        self.config = config
        self.correlation_id = f"{config.correlation_id_prefix}-{int(time.time())}"
        self.evidence_dir = Path(config.evidence_output_dir)
        self.evidence_dir.mkdir(exist_ok=True, parents=True)
        
        # Results storage
        self.checks: List[CheckResult] = []
        self.issues: List[Dict[str, Any]] = []
        self.remediation: List[str] = []
        self.artifacts: List[str] = []
        
        # Resolve environment variables in config
        self._resolve_env_vars()
    
    def _resolve_env_vars(self):
        """Resolve environment variable references in config"""
        if self.config.discord_bot_token and self.config.discord_bot_token.startswith("ENV:"):
            env_var = self.config.discord_bot_token[4:]
            self.config.discord_bot_token = os.getenv(env_var)
        
        if self.config.discord_app_id and self.config.discord_app_id.startswith("ENV:"):
            env_var = self.config.discord_app_id[4:]
            self.config.discord_app_id = os.getenv(env_var)
        
        if self.config.discord_guild_id and self.config.discord_guild_id.startswith("ENV:"):
            env_var = self.config.discord_guild_id[4:]
            self.config.discord_guild_id = os.getenv(env_var)
        
        if self.config.github_token and self.config.github_token.startswith("ENV:"):
            env_var = self.config.github_token[4:]
            self.config.github_token = os.getenv(env_var)
    
    def log(self, message: str, level: str = "INFO"):
        """Log message with timestamp and level"""
        timestamp = datetime.now(timezone.utc).strftime("%H:%M:%S")
        prefix = {
            "INFO": "‚ÑπÔ∏è",
            "SUCCESS": "‚úÖ",
            "WARNING": "‚ö†Ô∏è",
            "ERROR": "‚ùå",
            "DEBUG": "üîç"
        }.get(level, "  ")
        
        if self.config.verbose or level in ["ERROR", "SUCCESS"]:
            print(f"[{timestamp}] {prefix} {message}")
    
    def add_check(self, result: CheckResult):
        """Add a check result"""
        self.checks.append(result)
        
        # Log the result
        status_emoji = {
            "PASS": "‚úÖ",
            "FAIL": "‚ùå",
            "SKIP": "‚è≠Ô∏è",
            "WARNING": "‚ö†Ô∏è"
        }.get(result.status, "‚ùì")
        
        self.log(f"{status_emoji} {result.name}: {result.status}", 
                 "SUCCESS" if result.status == "PASS" else "WARNING" if result.status in ["SKIP", "WARNING"] else "ERROR")
        
        # Track issues
        if result.status in ["FAIL", "WARNING"]:
            self.issues.append({
                "check": result.name,
                "status": result.status,
                "error": result.error,
                "details": result.details
            })
    
    def add_remediation(self, step: str):
        """Add a remediation step"""
        self.remediation.append(step)
    
    # ============================================
    # Step 1: Prep + Discovery
    # ============================================
    
    def run_prep_and_discovery(self):
        """Prep + Discovery: Confirm repo, validate environment, check tokens"""
        self.log("=" * 60, "INFO")
        self.log("STEP 1: Prep + Discovery", "INFO")
        self.log("=" * 60, "INFO")
        
        # Check 1.1: Verify repository and base_ref
        start_time = time.time()
        try:
            result = subprocess.run(
                ["git", "rev-parse", "--verify", self.config.base_ref],
                cwd="/home/runner/work/Project-Valine/Project-Valine",
                capture_output=True,
                text=True,
                timeout=10
            )
            
            if result.returncode == 0:
                sha = result.stdout.strip()
                self.add_check(CheckResult(
                    name="Repository and Base Ref",
                    status="PASS",
                    primary_result={"base_ref": self.config.base_ref, "sha": sha},
                    duration_ms=(time.time() - start_time) * 1000,
                    details={"sha": sha}
                ))
            else:
                self.add_check(CheckResult(
                    name="Repository and Base Ref",
                    status="FAIL",
                    error=f"Cannot verify {self.config.base_ref}: {result.stderr}",
                    duration_ms=(time.time() - start_time) * 1000
                ))
                self.add_remediation(f"Verify base_ref '{self.config.base_ref}' exists in repository")
        except Exception as e:
            self.add_check(CheckResult(
                name="Repository and Base Ref",
                status="FAIL",
                error=str(e),
                duration_ms=(time.time() - start_time) * 1000
            ))
        
        # Check 1.2: Validate tokens present
        self._check_tokens_present()
        
        # Check 1.3: Validate URLs reachable
        self._check_urls_reachable()
        
        # Check 1.4: Discover validation scripts
        self._discover_validation_scripts()
    
    def _check_tokens_present(self):
        """Check that required tokens are present"""
        start_time = time.time()
        
        tokens_status = {
            "discord_bot_token": bool(self.config.discord_bot_token),
            "discord_app_id": bool(self.config.discord_app_id),
            "discord_guild_id": bool(self.config.discord_guild_id),
            "github_token": bool(self.config.github_token)
        }
        
        all_present = all(tokens_status.values())
        missing = [k for k, v in tokens_status.items() if not v]
        
        if all_present:
            self.add_check(CheckResult(
                name="Required Tokens Present",
                status="PASS",
                primary_result=tokens_status,
                duration_ms=(time.time() - start_time) * 1000,
                details={"all_tokens_present": True}
            ))
        else:
            self.add_check(CheckResult(
                name="Required Tokens Present",
                status="WARNING",
                error=f"Missing tokens: {', '.join(missing)}",
                primary_result=tokens_status,
                duration_ms=(time.time() - start_time) * 1000,
                details={"missing": missing}
            ))
            for token in missing:
                env_var = token.upper()
                self.add_remediation(f"Set environment variable {env_var}")
    
    def _check_urls_reachable(self):
        """Check that staging URLs are reachable"""
        for url in self.config.staging_urls:
            start_time = time.time()
            try:
                response = requests.head(
                    url,
                    timeout=self.config.timeout_http / 1000,
                    allow_redirects=True
                )
                
                status_code = response.status_code
                is_success = 200 <= status_code < 400
                
                self.add_check(CheckResult(
                    name=f"URL Reachable: {url}",
                    status="PASS" if is_success else "WARNING",
                    primary_result={"status_code": status_code, "url": url},
                    duration_ms=(time.time() - start_time) * 1000,
                    details={"status_code": status_code, "headers": dict(response.headers)}
                ))
                
                if not is_success:
                    self.add_remediation(f"Check URL {url} - returned status {status_code}")
            except Exception as e:
                self.add_check(CheckResult(
                    name=f"URL Reachable: {url}",
                    status="FAIL",
                    error=str(e),
                    duration_ms=(time.time() - start_time) * 1000
                ))
                self.add_remediation(f"Verify URL {url} is accessible from this environment")
    
    def _discover_validation_scripts(self):
        """Discover available validation scripts and workflows"""
        start_time = time.time()
        
        scripts_dir = Path("/home/runner/work/Project-Valine/Project-Valine/orchestrator/scripts")
        workflows_dir = Path("/home/runner/work/Project-Valine/Project-Valine/.github/workflows")
        
        discovered = {
            "validators": [],
            "workflows": [],
            "docs": []
        }
        
        # Find validator scripts
        if scripts_dir.exists():
            for script in scripts_dir.glob("*.py"):
                if "validator" in script.name or "phase5" in script.name:
                    discovered["validators"].append(str(script))
        
        # Find workflows
        if workflows_dir.exists():
            for workflow in workflows_dir.glob("*.yml"):
                if "phase5" in workflow.name or "validation" in workflow.name:
                    discovered["workflows"].append(str(workflow))
        
        self.add_check(CheckResult(
            name="Discover Validation Scripts",
            status="PASS",
            primary_result=discovered,
            duration_ms=(time.time() - start_time) * 1000,
            details=discovered
        ))
    
    # ============================================
    # Steps 3-8: Phase 5 Validation Runner
    # ============================================
    
    def run_phase5_validation(self):
        """Run Phase 5 validation steps 3-8 with double-check framework"""
        self.log("=" * 60, "INFO")
        self.log("STEPS 3-8: Phase 5 Staging Validation", "INFO")
        self.log("=" * 60, "INFO")
        
        # Step 3: Build + Artifact Check
        self._step3_build_artifact_check()
        
        # Step 4: Deploy-to-staging verification
        self._step4_deployment_verification()
        
        # Step 5: Health checks
        self._step5_health_checks()
        
        # Step 6: Smoke tests
        self._step6_smoke_tests()
        
        # Step 7: E2E/synthetics
        self._step7_e2e_tests()
        
        # Step 8: Observability checks
        self._step8_observability_checks()
    
    def _step3_build_artifact_check(self):
        """Step 3: Build + artifact check"""
        self.log("Step 3: Build + Artifact Check", "INFO")
        
        start_time = time.time()
        
        # Primary check: GitHub Actions recent workflow runs
        try:
            # Check if there are recent successful CI runs
            # For now, we'll check if the repository exists and has workflows
            workflows_dir = Path("/home/runner/work/Project-Valine/Project-Valine/.github/workflows")
            has_workflows = workflows_dir.exists() and list(workflows_dir.glob("*.yml"))
            
            primary_result = {"has_ci_workflows": bool(has_workflows)}
            
            # Secondary check: Look for build artifacts or package.json
            package_json = Path("/home/runner/work/Project-Valine/Project-Valine/package.json")
            has_package = package_json.exists()
            
            secondary_result = {"has_package_json": has_package}
            
            # Both checks should indicate a buildable project
            consistent = bool(has_workflows) == bool(has_package)
            
            status = "PASS" if (has_workflows and has_package) else "WARNING"
            
            self.add_check(CheckResult(
                name="Step 3: Build + Artifact Check",
                status=status,
                primary_result=primary_result,
                secondary_result=secondary_result,
                consistent=consistent,
                duration_ms=(time.time() - start_time) * 1000,
                details={
                    "workflows_found": len(list(workflows_dir.glob("*.yml"))) if has_workflows else 0,
                    "has_package_json": has_package
                }
            ))
            
            if not has_workflows:
                self.add_remediation("Add GitHub Actions workflows for CI/CD")
                
        except Exception as e:
            self.add_check(CheckResult(
                name="Step 3: Build + Artifact Check",
                status="FAIL",
                error=str(e),
                duration_ms=(time.time() - start_time) * 1000
            ))
    
    def _step4_deployment_verification(self):
        """Step 4: Deploy-to-staging verification"""
        self.log("Step 4: Deploy-to-Staging Verification", "INFO")
        
        start_time = time.time()
        
        try:
            # Primary check: Check AWS CLI available
            result = subprocess.run(
                ["aws", "--version"],
                capture_output=True,
                text=True,
                timeout=10
            )
            
            primary_result = {
                "aws_cli_available": result.returncode == 0,
                "version": result.stdout.strip() if result.returncode == 0 else None
            }
            
            # Secondary check: Check if SSM parameters accessible
            secondary_result = {"ssm_accessible": False}
            if result.returncode == 0:
                try:
                    ssm_result = subprocess.run(
                        ["aws", "ssm", "describe-parameters",
                         "--region", self.config.aws_region,
                         "--max-results", "1"],
                        capture_output=True,
                        text=True,
                        timeout=30
                    )
                    secondary_result["ssm_accessible"] = ssm_result.returncode == 0
                except Exception:
                    pass
            
            consistent = primary_result["aws_cli_available"]
            status = "PASS" if primary_result["aws_cli_available"] else "WARNING"
            
            self.add_check(CheckResult(
                name="Step 4: Deploy-to-Staging Verification",
                status=status,
                primary_result=primary_result,
                secondary_result=secondary_result,
                consistent=consistent,
                duration_ms=(time.time() - start_time) * 1000,
                details={"can_deploy": primary_result["aws_cli_available"]}
            ))
            
            if not primary_result["aws_cli_available"]:
                self.add_remediation("Install and configure AWS CLI for deployment")
                
        except Exception as e:
            self.add_check(CheckResult(
                name="Step 4: Deploy-to-Staging Verification",
                status="FAIL",
                error=str(e),
                duration_ms=(time.time() - start_time) * 1000
            ))
    
    def _step5_health_checks(self):
        """Step 5: Health checks"""
        self.log("Step 5: Health Checks", "INFO")
        
        for url in self.config.staging_urls:
            if "/health" not in url and "/api" not in url:
                continue
                
            start_time = time.time()
            
            try:
                # Primary check: Direct health endpoint
                primary_response = requests.get(
                    url,
                    timeout=self.config.timeout_http / 1000
                )
                
                primary_result = {
                    "status_code": primary_response.status_code,
                    "response_time_ms": primary_response.elapsed.total_seconds() * 1000,
                    "content_length": len(primary_response.content)
                }
                
                # Secondary check: HEAD request to same endpoint
                secondary_response = requests.head(
                    url,
                    timeout=self.config.timeout_http / 1000
                )
                
                secondary_result = {
                    "status_code": secondary_response.status_code,
                    "response_time_ms": secondary_response.elapsed.total_seconds() * 1000
                }
                
                # Check consistency
                consistent = (primary_response.status_code == secondary_response.status_code)
                status = "PASS" if (200 <= primary_response.status_code < 300) else "FAIL"
                
                self.add_check(CheckResult(
                    name=f"Step 5: Health Check - {url}",
                    status=status,
                    primary_result=primary_result,
                    secondary_result=secondary_result,
                    consistent=consistent,
                    duration_ms=(time.time() - start_time) * 1000,
                    details={
                        "url": url,
                        "both_successful": status == "PASS" and consistent
                    }
                ))
                
                if status != "PASS":
                    self.add_remediation(f"Fix health endpoint {url} - returned {primary_response.status_code}")
                elif not consistent:
                    self.add_remediation(f"Investigate inconsistency between GET and HEAD for {url}")
                    
            except Exception as e:
                self.add_check(CheckResult(
                    name=f"Step 5: Health Check - {url}",
                    status="FAIL",
                    error=str(e),
                    duration_ms=(time.time() - start_time) * 1000
                ))
                self.add_remediation(f"Debug connectivity to {url}: {str(e)}")
    
    def _step6_smoke_tests(self):
        """Step 6: Smoke tests"""
        self.log("Step 6: Smoke Tests", "INFO")
        
        start_time = time.time()
        
        # For smoke tests, we'll check if test files exist
        test_dirs = [
            Path("/home/runner/work/Project-Valine/Project-Valine/orchestrator/tests"),
            Path("/home/runner/work/Project-Valine/Project-Valine/tests")
        ]
        
        primary_result = {"test_files_found": 0}
        for test_dir in test_dirs:
            if test_dir.exists():
                test_files = list(test_dir.glob("test_*.py"))
                primary_result["test_files_found"] += len(test_files)
        
        # Secondary: Check if pytest is available
        try:
            result = subprocess.run(
                ["python3", "-m", "pytest", "--version"],
                capture_output=True,
                text=True,
                timeout=10
            )
            secondary_result = {
                "pytest_available": result.returncode == 0,
                "version": result.stdout.strip() if result.returncode == 0 else None
            }
        except Exception:
            secondary_result = {"pytest_available": False}
        
        has_tests = primary_result["test_files_found"] > 0
        can_run_tests = secondary_result.get("pytest_available", False)
        consistent = has_tests and can_run_tests
        
        status = "PASS" if consistent else "WARNING"
        
        self.add_check(CheckResult(
            name="Step 6: Smoke Tests",
            status=status,
            primary_result=primary_result,
            secondary_result=secondary_result,
            consistent=consistent,
            duration_ms=(time.time() - start_time) * 1000,
            details={"can_run_smoke_tests": consistent}
        ))
        
        if not has_tests:
            self.add_remediation("Add smoke test files to verify critical functionality")
        if not can_run_tests:
            self.add_remediation("Install pytest to run smoke tests")
    
    def _step7_e2e_tests(self):
        """Step 7: E2E/synthetic tests"""
        self.log("Step 7: E2E/Synthetic Tests", "INFO")
        
        start_time = time.time()
        
        # Check for E2E test infrastructure
        e2e_indicators = [
            Path("/home/runner/work/Project-Valine/Project-Valine/cypress"),
            Path("/home/runner/work/Project-Valine/Project-Valine/e2e"),
            Path("/home/runner/work/Project-Valine/Project-Valine/tests/e2e")
        ]
        
        primary_result = {"e2e_framework_found": False}
        for indicator in e2e_indicators:
            if indicator.exists():
                primary_result["e2e_framework_found"] = True
                primary_result["framework_path"] = str(indicator)
                break
        
        # Secondary: Check package.json for e2e dependencies
        package_json = Path("/home/runner/work/Project-Valine/Project-Valine/package.json")
        secondary_result = {"e2e_scripts_found": False}
        
        if package_json.exists():
            try:
                with open(package_json) as f:
                    package_data = json.load(f)
                    scripts = package_data.get("scripts", {})
                    secondary_result["e2e_scripts_found"] = any(
                        "e2e" in k or "cypress" in k for k in scripts.keys()
                    )
            except Exception:
                pass
        
        # E2E tests are optional, so this is a SKIP if not found, not a failure
        has_e2e = primary_result["e2e_framework_found"] or secondary_result["e2e_scripts_found"]
        status = "PASS" if has_e2e else "SKIP"
        
        self.add_check(CheckResult(
            name="Step 7: E2E/Synthetic Tests",
            status=status,
            primary_result=primary_result,
            secondary_result=secondary_result,
            consistent=True,
            duration_ms=(time.time() - start_time) * 1000,
            details={"e2e_available": has_e2e}
        ))
        
        if not has_e2e:
            self.add_remediation("Consider adding E2E tests for critical user flows (optional)")
    
    def _step8_observability_checks(self):
        """Step 8: Observability checks"""
        self.log("Step 8: Observability Checks", "INFO")
        
        start_time = time.time()
        
        # Primary: Check if CloudWatch logs accessible
        primary_result = {"cloudwatch_accessible": False}
        try:
            result = subprocess.run(
                ["aws", "logs", "describe-log-groups",
                 "--region", self.config.aws_region,
                 "--log-group-name-prefix", "/aws/lambda",
                 "--max-items", "1"],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                primary_result["cloudwatch_accessible"] = True
                try:
                    data = json.loads(result.stdout)
                    primary_result["log_groups_found"] = len(data.get("logGroups", []))
                except Exception:
                    pass
        except Exception as e:
            primary_result["error"] = str(e)
        
        # Secondary: Check if our specific log group exists
        secondary_result = {"target_log_group_exists": False}
        try:
            result = subprocess.run(
                ["aws", "logs", "describe-log-groups",
                 "--region", self.config.aws_region,
                 "--log-group-name-prefix", self.config.log_group_name],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                try:
                    data = json.loads(result.stdout)
                    log_groups = data.get("logGroups", [])
                    secondary_result["target_log_group_exists"] = any(
                        lg.get("logGroupName") == self.config.log_group_name
                        for lg in log_groups
                    )
                except Exception:
                    pass
        except Exception:
            pass
        
        consistent = primary_result.get("cloudwatch_accessible", False)
        status = "PASS" if consistent and secondary_result.get("target_log_group_exists", False) else "WARNING"
        
        self.add_check(CheckResult(
            name="Step 8: Observability Checks",
            status=status,
            primary_result=primary_result,
            secondary_result=secondary_result,
            consistent=consistent,
            duration_ms=(time.time() - start_time) * 1000,
            details={
                "can_access_logs": primary_result.get("cloudwatch_accessible", False),
                "target_log_group_exists": secondary_result.get("target_log_group_exists", False)
            }
        ))
        
        if not primary_result.get("cloudwatch_accessible", False):
            self.add_remediation("Configure AWS credentials with CloudWatch Logs read access")
        elif not secondary_result.get("target_log_group_exists", False):
            self.add_remediation(f"Verify log group {self.config.log_group_name} exists")
    
    # ============================================
    # Discord Slash Commands Validation
    # ============================================
    
    def run_discord_validation(self) -> Dict[str, Any]:
        """Validate Discord slash commands registration and visibility"""
        self.log("=" * 60, "INFO")
        self.log("Discord Slash Commands Validation", "INFO")
        self.log("=" * 60, "INFO")
        
        discord_results = {
            "commands": [],
            "missing": [],
            "outdated": [],
            "verified": [],
            "errors": []
        }
        
        # Skip if tokens not available
        if not self.config.discord_bot_token or not self.config.discord_app_id or not self.config.discord_guild_id:
            self.log("Discord tokens not configured, skipping Discord validation", "WARNING")
            self.add_check(CheckResult(
                name="Discord Slash Commands",
                status="SKIP",
                error="Discord credentials not provided",
                duration_ms=0
            ))
            return discord_results
        
        # Check 1: Fetch current guild commands
        start_time = time.time()
        try:
            headers = {
                "Authorization": f"Bot {self.config.discord_bot_token}",
                "Content-Type": "application/json"
            }
            
            url = f"https://discord.com/api/v10/applications/{self.config.discord_app_id}/guilds/{self.config.discord_guild_id}/commands"
            
            # Primary check: GET current commands
            primary_response = requests.get(url, headers=headers, timeout=self.config.timeout_http / 1000)
            
            if primary_response.status_code == 200:
                current_commands = primary_response.json()
                primary_result = {
                    "status_code": 200,
                    "command_count": len(current_commands),
                    "commands": [cmd.get("name") for cmd in current_commands]
                }
                
                discord_results["commands"] = current_commands
                discord_results["verified"] = primary_result["commands"]
                
                # Secondary check: Verify bot is in guild
                bot_url = "https://discord.com/api/v10/users/@me"
                secondary_response = requests.get(bot_url, headers=headers, timeout=self.config.timeout_http / 1000)
                
                secondary_result = {
                    "bot_authenticated": secondary_response.status_code == 200
                }
                
                if secondary_response.status_code == 200:
                    bot_info = secondary_response.json()
                    secondary_result["bot_username"] = bot_info.get("username")
                    secondary_result["bot_id"] = bot_info.get("id")
                
                consistent = True
                status = "PASS"
                
                self.add_check(CheckResult(
                    name="Discord Slash Commands - Fetch Current",
                    status=status,
                    primary_result=primary_result,
                    secondary_result=secondary_result,
                    consistent=consistent,
                    duration_ms=(time.time() - start_time) * 1000,
                    details={
                        "commands_found": primary_result["commands"],
                        "bot_authenticated": secondary_result.get("bot_authenticated", False)
                    }
                ))
                
                # Check if expected commands are present
                expected_commands = ["verify-latest", "verify-run", "diagnose", "debug-last"]
                missing = [cmd for cmd in expected_commands if cmd not in primary_result["commands"]]
                
                if missing:
                    discord_results["missing"] = missing
                    self.add_remediation(f"Register missing Discord commands: {', '.join(missing)}")
                    
            else:
                error_msg = f"Failed to fetch commands: {primary_response.status_code}"
                try:
                    error_data = primary_response.json()
                    error_msg += f" - {error_data.get('message', '')}"
                except Exception:
                    pass
                
                self.add_check(CheckResult(
                    name="Discord Slash Commands - Fetch Current",
                    status="FAIL",
                    error=error_msg,
                    duration_ms=(time.time() - start_time) * 1000
                ))
                
                discord_results["errors"].append(error_msg)
                
                if primary_response.status_code == 401:
                    self.add_remediation("Verify DISCORD_BOT_TOKEN is valid and not expired")
                elif primary_response.status_code == 403:
                    self.add_remediation("Verify bot has applications.commands scope in the guild")
                else:
                    self.add_remediation(f"Debug Discord API error: {error_msg}")
                    
        except Exception as e:
            self.add_check(CheckResult(
                name="Discord Slash Commands - Fetch Current",
                status="FAIL",
                error=str(e),
                duration_ms=(time.time() - start_time) * 1000
            ))
            discord_results["errors"].append(str(e))
            self.add_remediation(f"Debug Discord API connectivity: {str(e)}")
        
        return discord_results
    
    # ============================================
    # Report Generation
    # ============================================
    
    def generate_report(self, discord_results: Dict[str, Any]) -> ValidationReport:
        """Generate comprehensive validation report"""
        self.log("=" * 60, "INFO")
        self.log("Generating Validation Report", "INFO")
        self.log("=" * 60, "INFO")
        
        # Calculate summary statistics
        total_checks = len(self.checks)
        passed = sum(1 for c in self.checks if c.status == "PASS")
        failed = sum(1 for c in self.checks if c.status == "FAIL")
        warnings = sum(1 for c in self.checks if c.status == "WARNING")
        skipped = sum(1 for c in self.checks if c.status == "SKIP")
        
        summary = f"""
## Summary

**Total Checks:** {total_checks}
- ‚úÖ Passed: {passed}
- ‚ùå Failed: {failed}
- ‚ö†Ô∏è Warnings: {warnings}
- ‚è≠Ô∏è Skipped: {skipped}

**Discord Commands:** {len(discord_results.get('verified', []))} registered
**Issues Found:** {len(self.issues)}
**Remediation Steps:** {len(self.remediation)}
"""
        
        # Create report object
        report = ValidationReport(
            timestamp=datetime.now(timezone.utc).isoformat(),
            correlation_id=self.correlation_id,
            config=asdict(self.config) if self.config.redaction_enabled else {},
            steps=self.checks,
            discord_commands=discord_results,
            issues=self.issues,
            remediation=self.remediation,
            artifacts=self.artifacts,
            summary=summary
        )
        
        # Save report to file
        self._save_report(report)
        
        return report
    
    def _save_report(self, report: ValidationReport):
        """Save report to files"""
        timestamp_str = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
        
        # Save full JSON report
        json_path = self.evidence_dir / f"super_agent_report_{timestamp_str}.json"
        with open(json_path, 'w') as f:
            # Convert report to dict and apply redaction
            report_dict = {
                "timestamp": report.timestamp,
                "correlation_id": report.correlation_id,
                "config": redact_secrets(report.config) if self.config.redaction_enabled else report.config,
                "steps": [asdict(step) for step in report.steps],
                "discord_commands": report.discord_commands,
                "issues": report.issues,
                "remediation": report.remediation,
                "artifacts": report.artifacts,
                "summary": report.summary
            }
            json.dump(report_dict, f, indent=2)
        
        self.artifacts.append(str(json_path))
        self.log(f"Saved JSON report: {json_path}", "SUCCESS")
        
        # Generate Markdown report
        md_path = self.evidence_dir / f"super_agent_report_{timestamp_str}.md"
        self._generate_markdown_report(report, md_path)
        self.artifacts.append(str(md_path))
        self.log(f"Saved Markdown report: {md_path}", "SUCCESS")
    
    def _generate_markdown_report(self, report: ValidationReport, output_path: Path):
        """Generate Markdown formatted report"""
        with open(output_path, 'w') as f:
            f.write("# Phase 5 Staging Super-Agent Report\n\n")
            
            # Context
            f.write("## Context\n\n")
            f.write(f"**Timestamp:** {report.timestamp}\n")
            f.write(f"**Correlation ID:** {report.correlation_id}\n")
            f.write(f"**Repository:** {self.config.repo}\n")
            f.write(f"**Base Ref:** {self.config.base_ref}\n")
            f.write(f"**AWS Region:** {self.config.aws_region}\n\n")
            
            # Summary
            f.write(report.summary)
            f.write("\n")
            
            # Steps 3-8 Results
            f.write("## Steps 3-8 Validation Results\n\n")
            f.write("| Step | Status | Duration (ms) | Consistent | Details |\n")
            f.write("|------|--------|---------------|------------|----------|\n")
            
            for check in report.steps:
                status_emoji = {
                    "PASS": "‚úÖ",
                    "FAIL": "‚ùå",
                    "WARNING": "‚ö†Ô∏è",
                    "SKIP": "‚è≠Ô∏è"
                }.get(check.status, "‚ùì")
                
                consistent_emoji = "‚úÖ" if check.consistent else "‚ùå"
                duration = f"{check.duration_ms:.0f}"
                details = check.error if check.error else "OK"
                
                f.write(f"| {check.name} | {status_emoji} {check.status} | {duration} | {consistent_emoji} | {details} |\n")
            
            f.write("\n")
            
            # Double-Check Matrix
            f.write("## Double-Check Matrix\n\n")
            f.write("| Check | Primary | Secondary | Consistent |\n")
            f.write("|-------|---------|-----------|------------|\n")
            
            for check in report.steps:
                if check.primary_result is not None:
                    primary_status = "‚úÖ PASS" if check.status in ["PASS", "SKIP"] else "‚ùå FAIL"
                    secondary_status = "‚úÖ PASS" if check.secondary_result else "‚è≠Ô∏è N/A"
                    consistent = "‚úÖ" if check.consistent else "‚ùå"
                    
                    f.write(f"| {check.name} | {primary_status} | {secondary_status} | {consistent} |\n")
            
            f.write("\n")
            
            # Discord Commands
            f.write("## Discord Slash Commands\n\n")
            
            if report.discord_commands:
                f.write(f"**Registered Commands:** {len(report.discord_commands.get('verified', []))}\n\n")
                
                if report.discord_commands.get('verified'):
                    f.write("### Verified Commands\n\n")
                    for cmd in report.discord_commands['verified']:
                        f.write(f"- ‚úÖ `/{cmd}`\n")
                    f.write("\n")
                
                if report.discord_commands.get('missing'):
                    f.write("### Missing Commands\n\n")
                    for cmd in report.discord_commands['missing']:
                        f.write(f"- ‚ùå `/{cmd}` - Not registered\n")
                    f.write("\n")
            else:
                f.write("*Discord validation skipped - credentials not provided*\n\n")
            
            # Issues and Remediation
            if report.issues:
                f.write("## Issues Found\n\n")
                for i, issue in enumerate(report.issues, 1):
                    f.write(f"### Issue {i}: {issue['check']}\n\n")
                    f.write(f"**Status:** {issue['status']}\n")
                    if issue.get('error'):
                        f.write(f"**Error:** {issue['error']}\n")
                    f.write("\n")
            
            if report.remediation:
                f.write("## Remediation Playbook\n\n")
                for i, step in enumerate(report.remediation, 1):
                    f.write(f"{i}. {step}\n")
                f.write("\n")
            
            # Artifacts
            if report.artifacts:
                f.write("## Artifacts\n\n")
                for artifact in report.artifacts:
                    f.write(f"- `{artifact}`\n")
                f.write("\n")
            
            # Appendix
            f.write("## Appendix: Detailed Check Results\n\n")
            for check in report.steps:
                f.write(f"### {check.name}\n\n")
                f.write(f"**Status:** {check.status}\n")
                f.write(f"**Duration:** {check.duration_ms:.0f}ms\n")
                f.write(f"**Consistent:** {'Yes' if check.consistent else 'No'}\n")
                
                if check.primary_result:
                    f.write(f"\n**Primary Result:**\n```json\n{json.dumps(check.primary_result, indent=2)}\n```\n")
                
                if check.secondary_result:
                    f.write(f"\n**Secondary Result:**\n```json\n{json.dumps(check.secondary_result, indent=2)}\n```\n")
                
                if check.error:
                    f.write(f"\n**Error:** {check.error}\n")
                
                f.write("\n")
    
    # ============================================
    # Main Execution
    # ============================================
    
    def run(self) -> ValidationReport:
        """Run complete Phase 5 Super-Agent validation"""
        self.log("=" * 60, "INFO")
        self.log("Phase 5 Staging Super-Agent", "INFO")
        self.log(f"Correlation ID: {self.correlation_id}", "INFO")
        self.log("=" * 60, "INFO")
        
        start_time = time.time()
        
        try:
            # Step 1: Prep + Discovery
            self.run_prep_and_discovery()
            
            # Steps 3-8: Phase 5 Validation
            self.run_phase5_validation()
            
            # Discord Validation
            discord_results = self.run_discord_validation()
            
            # Generate Report
            report = self.generate_report(discord_results)
            
            total_duration = (time.time() - start_time) * 1000
            self.log(f"Validation complete in {total_duration:.0f}ms", "SUCCESS")
            
            # Print summary
            self.log("=" * 60, "INFO")
            self.log("VALIDATION SUMMARY", "INFO")
            self.log("=" * 60, "INFO")
            print(report.summary)
            
            if self.remediation:
                self.log("=" * 60, "WARNING")
                self.log("REMEDIATION REQUIRED", "WARNING")
                self.log("=" * 60, "WARNING")
                for i, step in enumerate(self.remediation, 1):
                    print(f"{i}. {step}")
            
            return report
            
        except Exception as e:
            self.log(f"Fatal error: {str(e)}", "ERROR")
            self.log(traceback.format_exc(), "ERROR")
            raise

# ============================================
# CLI Interface
# ============================================

def generate_default_config() -> str:
    """Generate default configuration file"""
    config = SuperAgentConfig()
    
    config_dict = {
        "repo": config.repo,
        "base_ref": config.base_ref,
        "staging": {
            "urls": config.staging_urls,
            "region": config.staging_region
        },
        "github": {
            "token": "ENV:GITHUB_TOKEN",
            "workflows": config.github_workflows
        },
        "discord": {
            "bot_token": "ENV:DISCORD_BOT_TOKEN",
            "app_id": "ENV:DISCORD_APP_ID",
            "guild_id": "ENV:DISCORD_GUILD_ID_STAGING"
        },
        "aws": {
            "region": config.aws_region,
            "ssm_prefix": config.ssm_parameter_prefix,
            "log_group": config.log_group_name,
            "lambda_function": config.lambda_function_name
        },
        "timeouts": {
            "action_dispatch": config.timeout_action_dispatch,
            "http": config.timeout_http,
            "discord_propagation": config.timeout_discord_propagation
        },
        "flags": {
            "dry_run": config.dry_run,
            "verbose": config.verbose,
            "redaction_enabled": config.redaction_enabled
        },
        "evidence_output_dir": config.evidence_output_dir,
        "correlation_id_prefix": config.correlation_id_prefix
    }
    
    output_path = Path("super_agent_config.json")
    with open(output_path, 'w') as f:
        json.dump(config_dict, f, indent=2)
    
    return str(output_path)

def load_config(config_path: str) -> SuperAgentConfig:
    """Load configuration from JSON file"""
    with open(config_path) as f:
        data = json.load(f)
    
    config = SuperAgentConfig()
    
    # Map JSON structure to config object
    config.repo = data.get("repo", config.repo)
    config.base_ref = data.get("base_ref", config.base_ref)
    
    if "staging" in data:
        config.staging_urls = data["staging"].get("urls", config.staging_urls)
        config.staging_region = data["staging"].get("region", config.staging_region)
    
    if "github" in data:
        config.github_token = data["github"].get("token", config.github_token)
        config.github_workflows = data["github"].get("workflows", config.github_workflows)
    
    if "discord" in data:
        config.discord_bot_token = data["discord"].get("bot_token", config.discord_bot_token)
        config.discord_app_id = data["discord"].get("app_id", config.discord_app_id)
        config.discord_guild_id = data["discord"].get("guild_id", config.discord_guild_id)
    
    if "aws" in data:
        config.aws_region = data["aws"].get("region", config.aws_region)
        config.ssm_parameter_prefix = data["aws"].get("ssm_prefix", config.ssm_parameter_prefix)
        config.log_group_name = data["aws"].get("log_group", config.log_group_name)
        config.lambda_function_name = data["aws"].get("lambda_function", config.lambda_function_name)
    
    if "timeouts" in data:
        config.timeout_action_dispatch = data["timeouts"].get("action_dispatch", config.timeout_action_dispatch)
        config.timeout_http = data["timeouts"].get("http", config.timeout_http)
        config.timeout_discord_propagation = data["timeouts"].get("discord_propagation", config.timeout_discord_propagation)
    
    if "flags" in data:
        config.dry_run = data["flags"].get("dry_run", config.dry_run)
        config.verbose = data["flags"].get("verbose", config.verbose)
        config.redaction_enabled = data["flags"].get("redaction_enabled", config.redaction_enabled)
    
    config.evidence_output_dir = data.get("evidence_output_dir", config.evidence_output_dir)
    config.correlation_id_prefix = data.get("correlation_id_prefix", config.correlation_id_prefix)
    
    return config

def main():
    """Main CLI entry point"""
    parser = argparse.ArgumentParser(
        description="Phase 5 Staging Super-Agent - Speedrun validation with double-check framework"
    )
    
    subparsers = parser.add_subparsers(dest="command", help="Command to execute")
    
    # Generate config command
    subparsers.add_parser("generate-config", help="Generate default configuration file")
    
    # Run command
    run_parser = subparsers.add_parser("run", help="Run Phase 5 Super-Agent validation")
    run_parser.add_argument("--config", required=True, help="Path to configuration file")
    run_parser.add_argument("--verbose", action="store_true", help="Enable verbose output")
    run_parser.add_argument("--dry-run", action="store_true", help="Dry run mode (no modifications)")
    
    args = parser.parse_args()
    
    if args.command == "generate-config":
        config_path = generate_default_config()
        print(f"‚úÖ Generated default configuration: {config_path}")
        print("Edit the file with your values and run: python phase5_super_agent.py run --config super_agent_config.json")
        return 0
    
    elif args.command == "run":
        # Load configuration
        config = load_config(args.config)
        
        # Override with CLI flags
        if args.verbose:
            config.verbose = True
        if args.dry_run:
            config.dry_run = True
        
        # Run agent
        agent = Phase5SuperAgent(config)
        report = agent.run()
        
        # Exit with appropriate code
        failed = sum(1 for c in report.steps if c.status == "FAIL")
        if failed > 0:
            print(f"\n‚ùå Validation completed with {failed} failures")
            return 1
        else:
            print("\n‚úÖ Validation completed successfully")
            return 0
    
    else:
        parser.print_help()
        return 1

if __name__ == "__main__":
    sys.exit(main())
